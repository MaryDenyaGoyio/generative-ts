doc: gp_extrap
data:
  dataset: gp
  classify: &classify False
  classify_type: &classify_type per_seq
  T_val: 150
  max_val_samples: 3  # GP 데이터에 맞게 증가
  sample_tp: null
  cut_tp: null
  extrap: True
  channel: &channel 1

optim:
  lr: 0.001
  weight_decay: 0.0
  epochs: 1000
  batch_size: 128
  eval_iter: 10

model:
  sigma: 0.01
  z_dim: &z_dim 1  # Back to original simple case
  in_channels: *channel
  bidirectional: False
  classifier: *classify
  classifier_type: *classify_type
  linear_cls: False
  decoder:
    use_spatial: False
    activation: identity
    prior:
      d_input: *z_dim #zdim
      aux_channels: 0 #input, will be concatenated to z
      d_state: 16  # Back to original small model
      d_output: *z_dim #zdim
      d_model: 16  # Back to original small model
      # d_temb: 64
      n_layers: 4
      backbone: autoreg
      use_unet: False
      pool: []
      expand: 2
      ff: 2
      bidirectional: False
      dropout: 0.0
      s4_type: s4
      use_latent: True
      latent_type: split
      lr: 0.001
    decoder:
      d_input: *z_dim #zdim
      aux_channels: 0 #input, will be concatenated to z
      d_state: 16  # Back to original small model
      d_output: *channel
      d_model: 16  # Back to original small model
      # d_temb: 64
      n_layers: 4
      backbone: autoreg
      use_unet: False
      pool: []
      expand: 2
      ff: 2
      bidirectional: False
      dropout: 0.0
      s4_type: s4
      use_latent: False
      latent_type: none
      aux_out: 0
      lr: 0.001

  encoder:
    use_spatial: False
    posterior:
      d_input: *channel
      aux_channels: 0
      d_state: 16  # Back to original small model
      d_output: *z_dim #zdim
      d_model: 16  # Back to original small model
      # d_temb: 64
      n_layers: 4
      backbone: autoreg
      use_unet: False
      pool: []
      expand: 2
      ff: 2
      bidirectional: False
      dropout: 0.0
      s4_type: s4
      use_latent: True
      latent_type: split
      lr: 0.001
      